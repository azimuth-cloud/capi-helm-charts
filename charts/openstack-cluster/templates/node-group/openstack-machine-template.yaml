{{/*
  Machine templates are immutable, so we need to make a new one when the spec changes.
  To do this, we create a new template whenever the checksum of the spec changes.
*/}}
{{- define "openstack-cluster.nodegroup.mt.spec" -}}
{{- $ctx := index . 0 -}}
{{- $nodeGroup := index . 1 -}}
template:
  spec:
    identityRef:
      name: {{ include "openstack-cluster.cloudCredentialsSecretName" $ctx }}
      cloudName: openstack
    flavor: {{ $nodeGroup.machineFlavor | required (printf "no flavor specified for node group '%s'" $nodeGroup.name) }}
    {{- with $ctx.Values.machineSSHKeyName }}
    sshKeyName: {{ . }}
    {{- end }}
    {{- if or $nodeGroup.machineConfigDrive $nodeGroup.additionalBlockDevices }}
    configDrive: true
    {{- end }}
    {{- with $nodeGroup.machineRootVolume }}
    {{- if .diskSize }}
    rootVolume:
      sizeGiB: {{ .diskSize }}
      {{- with .volumeType }}
      type: {{ . }}
      {{- end }}
      availabilityZone:
        {{- if .availabilityZone }}
        from: Name
        name: {{ .availabilityZone }}
        {{- else }}
        from: Machine
        {{- end }}
    {{- end }}
    {{- end }}
    image:
      {{- if $nodeGroup.machineImageId }}
      id: {{ $nodeGroup.machineImageId }}
      {{- else if $nodeGroup.machineImage }}
      filter:
        name: {{ tpl $nodeGroup.machineImage $ctx }}
      {{- else if $ctx.Values.machineImageId }}
      id: {{ $ctx.Values.machineImageId }}
      {{- else if $ctx.Values.machineImage }}
      filter:
        name: {{ tpl $ctx.Values.machineImage $ctx }}
      {{- else }}
      {{- fail "One of nodeGroupDefaults.machineImageId, nodeGroupDefaults.machineImage, machineImageId or machineImage is required" }}
      {{- end }}
    {{- with $nodeGroup.additionalBlockDevices }}
    additionalBlockDevices:
      {{- range $name, $blockDevice := . }}
      - name: {{ $name }}
        sizeGiB: {{ required "size is required for a block device" $blockDevice.size }}
        storage:
          type: {{ default "Volume" $blockDevice.type }}
          volume:
            {{- with $blockDevice.volumeType }}
            type: {{ . }}
            {{- end }}
            availabilityZone:
              {{- if $blockDevice.availabilityZone }}
              from: Name
              name: {{ $blockDevice.availabilityZone }}
              {{- else }}
              from: Machine
              {{- end }}
      {{- end }}
    {{- end }}
    {{- with $nodeGroup.machineNetworking.ports }}
    ports: {{ include "openstack-cluster.convert.neutronPortsFilter" . | nindent 6 }}
    {{- end }}
    {{- with $nodeGroup.serverGroupId }}
    serverGroup:
      id: {{ . }}
    {{- end }}
    {{- with mergeOverwrite $ctx.Values.machineMetadata $nodeGroup.machineMetadata }}
    serverMetadata:
      {{- range $k, $v := . }}
      - key: {{ quote $k }}
        value: {{ quote $v }}
      {{- end }}
    {{- end }}
{{- end }}

{{- define "openstack-cluster.nodegroup.mt.checksum" -}}
{{- include "openstack-cluster.nodegroup.mt.spec" . | sha256sum }}
{{- end }}

{{- define "openstack-cluster.nodegroup.mt.name" -}}
{{- $ctx := index . 0 }}
{{- $nodeGroup := index . 1 }}
{{- $checksum := include "openstack-cluster.nodegroup.mt.checksum" . }}
{{- include "openstack-cluster.componentName" (list $ctx $nodeGroup.name) }}-{{ trunc 8 $checksum }}
{{- end }}

{{- range $nodeGroupOverrides := .Values.nodeGroups }}
{{- $nodeGroup := deepCopy $.Values.nodeGroupDefaults | mustMerge $nodeGroupOverrides }}
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: OpenStackMachineTemplate
metadata:
  name: {{ include "openstack-cluster.nodegroup.mt.name" (list $ $nodeGroup) }}
  labels:
    {{- include "openstack-cluster.componentLabels" (list $ "worker") | nindent 4 }}
    {{ $.Values.projectPrefix }}/node-group: {{ $nodeGroup.name }}
  annotations:
    {{ $.Values.projectPrefix }}/template-checksum: {{ include "openstack-cluster.nodegroup.mt.checksum" (list $ $nodeGroup) }}
    # Cluster API complains when old templates disappear before it has rolled all the machines over
    # When deploying with Helm, leave the resource behind and let Cluster API clean it up
    helm.sh/resource-policy: keep
    # Allow Argo to clean up old templates by ignoring the non-controller owner references,
    #Â but only after the cluster has become healthy again
    argocd.argoproj.io/sync-options: "ControllerReferencesOnly=true,PruneLast=true"
spec: {{ include "openstack-cluster.nodegroup.mt.spec" (list $ $nodeGroup) | nindent 2 }}
{{- end }}
